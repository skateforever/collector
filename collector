#!/bin/bash
#
# collector my script for reconnaissance during
# my job as pentester or as a hobby doing bug bounty
#

collector_command_line="$0 $*"

banner(){
# Always print the banner
echo -e "                                 __ __             __
                    ____ ____   / // /___   ____ _/ /_ ____   ____
                   / __// __ \ / // // _ \ / __//_ __// __ \ / __/ 
                  / /__/ /_/ // // // ___// /__ / /_ / /_/ // /  
                  \___/\____//_//_/ \___/ \___/ \__/ \____//_/   

                                                 by skate_forever
"
}

collector_path=$(dirname "$0")

if [ -s "${collector_path}/collector.cfg" ]; then
    source "${collector_path}/collector.cfg"
else
    banner
    echo -e "Please ${red}make sure${reset} you have the ${yellow}collector.cfg${reset} file."
    echo -e "${yellow}You need this to set the tools parameters${reset}!"
    echo -e "You will set aquatone, gobuster, dirsearch threads and others.\n"
    exit 1
fi

if [ -z "${pentest_dir}" ] ; then
    banner
    echo -e "Please ${red}make sure${reset} that the ${yellow}pentest_dir${reset} variable is indicating the location,"
    echo -e "for the tools and wordlists used by the ${yellow}collector${reset} in the ${yellow}collector.cfg${reset} configuration file.\n"
    exit 1
fi

# Verifying if all binaries there are in the system
count=0
for binary in amass aquatone censys-subdomain-finder.py diff dig dirsearch dnssearch git-dumper \
   gobuster host html2text jq katana massdns nmap notify nuclei shodan subfinder waybackurls whois; do
   if ! command -v "${binary}" > /dev/null 2>&1 ; then
      echo -e "The ${red}${binary} does not exist${reset} on the system!"
      ((count += 1))
   fi
done

# Get the correct path to use chromium with aquatone
for binary in chromium chromium-browser; do
    if [ -x "$(command -v ${binary})" ] ; then
       chromium_bin="$(command -v ${binary})"
    fi
done

if [ -z "${chromium_bin}" ]; then
    echo -e "The ${red}chromium does not exist${reset} on the system!"
    ((count += 1))
fi

if [ "${count}" -gt 0 ]; then
    echo -e "Please, ${yellow}make sure${reset} you got all tools (binaries and scripts)."
    echo -e "You could use the ${yellow}get-tools.sh${reset} to get all binaries and scripts!"
    unset count
    exit 1
fi

if [ -n "${shodan_use}" ]; then
    shodan_use=$(echo "${shodan_use}" | tr '[:upper:]' '[:lower:]')
    if [ "${shodan_use}" == "yes" ]; then
        [[ -n "${shodan_just_scan_main_domain}" ]] && \
            shodan_just_scan_main_domain=$(echo "${shodan_just_scan_main_domain}" | tr '[:upper:]' '[:lower:]')
        if [ -n "${shodan_apikey}" ] && [ ! -s ~/.shodan/api_key ]; then
            shodan init "${shodan_apikey}" > /dev/null
        fi
    fi
fi

# Script usage description
usage(){
    (
    echo -e "Basic usage:"
    echo -e "       ${yellow}$0${reset} ${green}-d domain.com -wsd -wtd curl${reset}"
    echo -e "       ${yellow}$0${reset} ${green}-dl /path/file/domain_list.txt -wsd -wtd curl${reset}"
    echo -e "       ${yellow}$0${reset} ${green}-u http://domain.com${reset}\n"
    echo "Options: "
    echo -e "\t-d  |--domain               - Specify a valid domain [${red}needed${reset}]."
    echo -e "\t-dl |--domain-list          - Specify a valid domain [${red}needed${reset}]."
    echo -e "\t-e  |--exclude-domains      - Specify excluded subdomains after all treated files [${red}used only with -d|--domain${reset}]:"
    echo -e "\t-el |--exclude-domains-list - Specify excluded subdomains from a file after all treated files [${red}used only with -d|--domain${reset}]:"
    echo -e "\t\t\t\t      ${yellow}use -e domain1.com,domain2.com or --exclude-domains domain1.com,domain2.com${reset}"
    echo -e "\t-k  |--kill                 - Will kill the current execution of collector, you need to specify the domain as argument."
    echo -e "\t-ka |--kill-all             - Will kill the current execution of collector and delete the directory of results from current execution, you need to specify the domain as argument."
    echo -e "\t-l  |--limit-urls           - Specify the url quantity to run dirsearch and gobuster for dirs and files enumeration [${red}used only with -d|--domain${reset}]:"
    echo -e "\t\t\t\t      ${yellow}use -l 10 or --limit-urls 10${reset}"
    echo -e "\t-o  |--output               - This option when specified will use the directory to save the output of collector script if omitted the default value is:"
    echo -e "\t\t\t\t      ${yellow}${PWD}${reset}"
    echo -e "\t\t\t\t    - This option as well as others can be configured on collector.cfg, variable output_dir or use the parameters like:"
    echo -e "\t\t\t\t      ${yellow}use -o /path/of/output or --output-dir /path/of/output${reset}"
    echo -e "\t-p  |--proxy                - This option will use a provided proxy (with port) to avoid or bypass WAF block."
    echo -e "\t\t\t\t      ${yellow}use -p or --proxy${reset}"
    echo -e "\t-r  |--recon                - Will execute a recon until you find out what domains are webpage: ${red}used only with -d|--domain${reset} WITHOUT ${red}-wd|--web-data${reset}."
    echo -e "\t-s  |--subdomain-brute      - Specify the wordlist to put in dns_wordlist array and execute gobuster and dnssearch brute force [${red}used only with -d|--domain${reset}]"
    echo -e "\t\t\t\t      by default the array is empty and not execute amass, gobuster and dnssearch. This option take a long time to finish, use this own your need!"
    echo -e "\t\t\t\t      The success of use those tools is a good wordlist:"
    echo -e "\t\t\t\t      ${yellow}use -s /path/to/wordlist1,/path/to/wordlist2 or --subdomain-brute /path/to/wordlist1,/path/to/wordlist2${reset}"
    echo -e "\t-u  |--url                  - Specify a valid url [${red}needed${reset}]."
    echo -e "\t-wd |--web-data             - Will execute a web data dig after execution of collector with recon option (${red}-re|--recon${reset}): used only with ${red}-d|--domain${reset} WITHOUT ${red}-re|--recon${reset}."
    echo -e "\t-wld|--web-long-detection   - Will execute the long list of ports setup in collector.cfg as variable web_port_long_detection." 
    echo -e "\t-wsd|--web-short-detection  - Will execute the short list of ports setup in collector.cfg as variable web_port_short_detection."
    echo -e "\t-wtd|--web-tool-detection   - You need to inform what tool to perform web application detection the tool can be ${bold}${yellow}curl${reset}${normal} OR ${bold}${yellow}httpx${reset}${normal}."
    echo -e "\t-ww |--web-wordlists        - Specity more wordlists to put in web_wordlist array, by default we use the $(echo ${web_tools_dir} | sed "s/\/home\/.*\/pentest/~\/pentest/")/dirsearch/db/dicc.txt"
    echo -e "\t\t\t\t      as the first wordlist to enumerate dirs and files from website."
    echo -e "\t\t\t\t      ${yellow}use -ww /path/to/wordlist1,/path/to/wordlist2 or --web-wordlists /path/to/wordlist1,/path/to/wordlist2${reset}"
    echo ""
    ) 1>&2; exit 1
}

check_argument(){
    options+=(-d --domain -dl --domain-list -e --exclude-domains -el --exclude-domains-list -k -kill -ka --kill-all -l --limit-urls -o --output -p --proxy -r --recon)
    options+=(-s --subdomain-brute -u --url -wd --web-data -wld --web-long-detection -wsd --web-short-detection -wtd --web-tool-detection -ww --web-wordlists)
    if [[ "${options[*]}" =~ $2 ]]; then
        echo -e "The argument of ${yellow}\"$1\"${reset} it can not be ${red}\"$2\"${reset}, please, ${yellow}specify a valid one${reset}.\n"
        banner
        usage
    fi
}

kill_collector(){
    for pid in $(ps aux | grep "${1::1}${1:1}" | awk '{print $2}'); do
        kill -9 "${pid}" > /dev/null 2>&1
    done
    exit 0
}

args_count=0
only_recon="no"
only_web_data="no"

while [ $# -ne 0 ]; do
    (( args_count += 1 ))
    case $1 in
        -d|--domain)
            check_argument "$1" "$2"
            if [[ -n "${url_2_verify}" ]]; then
                banner
                echo -e "You can only use \"-d|--domain\" or \"-u|--url\", never both together!\n"
                usage
            elif [[ -s "${domain_list}" ]]; then
                banner
                echo -e "You can only use \"-d|--domain\" or \"-dl|--domain-list\", never both together!\n"
                usage
            else
                if [[ $(host -t A "$2" | grep -E "has.address" | awk '{print $4}' | grep -E "${IPv4_regex}$" > /dev/null 2>&1; echo $?) -eq 0 ]]; then
                    domain="$2"
                    unset directories_structure
                    directories_structure="domain"
                    shift 2
                else
                    banner
                    echo -e "You need specify a valid domain!\n"
                    usage
                fi
            fi
            ;;
        -dl|--domain-list)
            check_argument "$1" "$2"
            if [[ -n "${url_2_verify}" ]]; then
                banner
                echo -e "You can only use \"-dl|--domain-list\" or \"-u|--url\", never both together!\n"
                usage
            elif [[ -s "${domain_list}" ]]; then
                banner
                echo -e "You can only use \"-dl|--domain-list\" or \"-d|--domain\", never both together!\n"
                usage
            else
                if [ -s "$2" ]; then
                    domain_list=$2
                    unset directories_structure
                    directories_structure="domain"
                    shift 2
                else
                    banner
                    echo -e "Please provide a valid file with domains.\n"
                    usage
                fi
            fi
            ;;
        -e|--exclude-domains)
            check_argument "$1" "$2"
            if [[ -n "${url_2_verify}" ]]; then
                banner
                echo -e "You can only use this (-e|--exlude-domains) option with \"-d|--domain\"!\n"
                usage
            fi
            set -f
            IFS=","
            excluded+=("$2")
	        unset IFS
            shift 2
            ;;
        -el|--exclude-domains-list)
            if [ -s "$2" ]; then
                exclude_domains_list="$2"
                shift 2
            fi
            ;;
        -k|--kill)
            check_argument "$1" "$2"
            if [ -z "$2" ]; then
                banner
                echo "You need to specify a domain to kill the execution!"
                exit 1
            else
                kill_collector "$2"
            fi
            ;;
        -kr|--kill-remove)
            check_argument "$1" "$2"
            if [ -z "$2" ]; then
                banner
                echo "You need to specify a domain to kill the execution!"
                exit 1
            else
                kill_collector "$2"
                rm -rf "$(find / -iname "$(find / -iname "$2" -type d -exec ls -1 {} \; 2>/dev/null | grep recon_ | tail -n1)" -type d 2> /dev/null)"
            fi
            ;;
        -l|--limit-urls)
            check_argument "$1" "$2"
            if [[ -n "${url_2_verify}" ]]; then
                banner
                echo -e "You can only use this (-l|--limit-urls) option with \"-d|--domain\"!\n"
                usage
            fi
            if [[ -n "$2" && "$2" == ?(-)+([0-9]) ]]; then
                limit_urls="$2"
                shift 2
            else
                banner
                echo -e "Specify the total number of URLs you want to test!\n"
                usage
            fi
            ;;
        -o|--output)
            check_argument "$1" "$2"
            [ ! -d "$2" ] && mkdir -p "$2" 2> /dev/null
            if [[ $(cd "$2" > /dev/null 2>&1 ; echo "$?") -eq 0 ]] && [[ $(touch "$2/permission_to_write.txt" > /dev/null 2>&1; echo "$?") -eq 0 ]]; then
                unset output_dir
                output_dir="$(echo "$2" | sed -e 's/\/$//')"
                shift 2
                rm -rf "${output_dir}/permission_to_write.txt"
            else
                banner
                echo -e "Please, you need to specify a ${yellow}valid directory you own or have access permission${reset}!\n"
                usage
            fi
            ;;
        -p|--proxy)
            check_argument "$1" "$2"
            use_proxy="yes"
            proxy_ip="$(echo "$2" | sed -E 's/^\s*.*:\/\///g')"
            shift 2
            ;;
        -r|--recon)
            if [[ -n "${only_web_data}" ]] && [[ "${only_web_data}" == "yes"  ]]; then
                banner
                echo -e "You can't use this (-re|--recon) option with \"-wd|--web-data\"!\n"
                usage
            fi
            if [[ -n "${url_2_verify}" ]]; then
                banner
                echo -e "With this option (-re|--recon) You can only use \"-d|--domain\"!\n"
                usage
            fi
            only_recon=yes
            shift
            ;;
        -s|--subdomain-brute)
            check_argument "$1" "$2"
            if [[ -n "${url_2_verify}" ]]; then
                banner
                echo -e "You can only use this (-s|--subdomain-brute) option with \"-d|--domain\"!\n"
                usage
            fi
            set -f
            IFS=","
            dns_wordlists+=("$2")
            unset IFS
            shift 2
            ;;
        -u|--url)
            check_argument "$1" "$2"
            if [[ -n "${domain}" ]]; then
                banner
                echo -e "You can only use \"-u|--url\" or \"-d|--domain\", never both together!\n"
                usage
            elif [[ -s "${domain_list}" ]]; then
                banner
                echo -e "You can only use \"-u|--url\" or \"-dl|--domain-list\", never both together!\n"
                usage
            else
                [[ -n "$2" ]] && status_code=$(curl -o /dev/null -kLs -w "%{http_code}" "$2")
                if [[ -z ${status_code} || "${status_code}" -eq "000" ]];then
                    banner
                    echo -e "You need specify a valid URL!\n"
                    usage
                else
                    url_2_verify=$2
                    unset directories_structure
                    directories_structure="url"
                    shift 2
                fi
            fi
            unset status_code
            ;;
        -wd|--web-data)
            if [[ -n "${only_recon}" ]] && [[ "${only_recon}" == "yes"  ]]; then
                banner
                echo -e "You can't use this (-wd|--web-data) option with \"-re|--recon\"!\n"
                usage
            fi
            if [[ -n "${url_2_verify}" ]]; then
                banner
                echo -e "With this option (-wd|--web-data) You can only use \"-d|--domain\"!\n"
                usage
            fi
            only_web_data=yes
            shift
            ;;
        -wld|--web-long-detection)
            if [ "${#web_port_detect[@]}" -eq 0 ]; then
                web_port_detect=("${web_port_long_detection[@]}")
            else
                diff_array=$(diff <(printf "%s\n" "${web_port_detect[@]}") <(printf "%s\n" "${web_port_long_detection[@]}"))
                if [[ "${#web_port_detect[@]}" -ne 0 ]] && [[ -n ${diff_array} ]]; then
                    banner
                    echo -e "You need to specify just sort or long web port detection, not both!\n"
                    unset web_port_detect
                    usage
                fi
            fi
            shift
            ;;
        -wsd|--web-short-detection)
            if [ "${#web_port_detect[@]}" -eq 0 ]; then
                web_port_detect=("${web_port_short_detection[@]}")
            else
                diff_array=$(diff <(printf "%s\n" "${web_port_detect[@]}") <(printf "%s\n" "${web_port_short_detection[@]}"))
                if [[ "${#web_port_detect[@]}" -ne 0 ]] && [[ -n ${diff_array} ]]; then
                    banner
                    echo -e "You need to specify just sort or long web port detection, not both!\n"
                    unset web_port_detect
                    usage
                fi
            fi
            shift
            ;;
        -wtd|--web-tool-detection)
            check_argument "$1" "$2"
            if [[ "curl" != "$2" && "httpx" != "$2" ]] ; then
                banner
                echo -e "You need to inform one of these tools curl or httpx!\n"
                usage
            else
                unset web_tool_detection
                web_tool_detection="$2"
                if [ "${web_tool_detection}" == "httpx" ]; then
                    if ! command -v httpx > /dev/null 2>&1 ; then
                        banner
                        echo -e "The ${red}httpx does not exist${reset} on the system!"
                        echo -e "Please install the httpx and put in your PATH!"
                        exit 1
                    fi
                fi
                shift 2
            fi
            ;;
        -ww|--web-wordlists)
            check_argument "$1" "$2"
            set -f
            IFS=","
            web_wordlists+=("$2")
            unset IFS
            shift 2
            ;;
        -?*)
            banner
            usage
            ;;
        *)
            break
    esac
done

# Checking if the script has the main parameters needed
if [[ -z "${url_2_verify}" ]] && [[ -z "${domain}" ]] && [[ ! -s "${domain_list}" ]]; then
    banner
    echo -e "You need at least one option \"-u|--url\", \"-d|--domain\" OR \"-dl|--domain-list\" to execute this script!\n"
    usage
fi

# Verify the if exist the default resolvers list
if [ ! -s "${massdns_resolvers_file}" ]; then
    banner
    echo "The resolvers file does not exist, please fix it, downloading from this source: "
    echo -e "\n\thttps://public-dns.info/nameservers.txt"
    echo " "
    echo -e "After the download put the path to nameservers.txt file in massdns_resolvers_file variable in collector.cfg file.\n"
    usage
fi

# Verify the if exist the default wordlist for web
if [ ${#web_wordlists[@]} -eq 0 ]; then
    banner
    echo -e "Please, ${yellow}make sure${reset} you have the default wordlists to web directory and file discovery!\n"
    usage
fi

# Create the structure
create_initial_directories_structure(){

    if [ "${directories_structure}" == "domain" ]; then
        # Create all dirs necessaries to report and recon for domain
        mkdir -p "${output_dir}/${domain}"/{log,"domain_${date_recon}"}
        log_dir="${output_dir}/${domain}/log"
        log_execution_file="${log_dir}/domain_${date_recon}.log"
        recon_dir="${output_dir}/${domain}/domain_${date_recon}"
        # secundaries directories
        mkdir -p "${recon_dir}"/{aquatone,nmap,nuclei,report,tmp,web-data,web-params,web-tech}
        aquatone_files_dir="${recon_dir}/aquatone"
        nmap_dir="${recon_dir}/nmap"
        nuclei_dir="${recon_dir}/nuclei"
        report_dir="${recon_dir}/report"
        shodan_dir="${recon_dir}/shodan"
        if [[ "${shodan_use}" == "yes" ]] && [[ ! -d "${shodan_dir}" ]]; then
            mkdir -p "${shodan_dir}"
        fi
        tmp_dir="${recon_dir}/tmp"
        web_data_dir="${recon_dir}/web-data"
        web_params_dir="${recon_dir}/web-params"
        web_tech_dir="${recon_dir}/web-tech"
    fi

    if [ "${directories_structure}" == "url" ]; then
        # Create all dirs necessaries to report and recon for url
        mkdir -p "${output_dir}"/"${url_domain}"/{log,"url_${date_recon}"}
        log_dir="${output_dir}/${url_domain}/log"
        log_execution_file="${log_dir}/url_${date_recon}.log"
        recon_dir="${output_dir}/${url_domain}/url_${date_recon}"
    
        # secundaries directories
        mkdir -p "${recon_dir}/${url_base}"/{report,aquatone}
        report_dir="${recon_dir}/${url_base}/report"
        aquatone_files_dir="${recon_dir}/${url_base}/aquatone"
        nuclei_dir="${report_dir}"
        shodan_dir="${report_dir}"
        tmp_dir="${report_dir}"
        web_data_dir="${report_dir}"
        web_params_dir="${report_dir}"
        web_tech_dir="${report_dir}"
    fi

    nuclei_scan_file="${nuclei_dir}/nuclei_scan.result"
    nuclei_web_fuzzing_file="${nuclei_dir}/nuclei_web_fuzzing.result"
}

# Checking if the essencial functions there are
for file in diff_recon domain_recon emails_recon infra_recon vhost_check web_data web_detect_page web_git_rebuild; do
    function="${collector_path}/functions/${file}.sh"
    if [ -s "${function}" ]; then
        source "${function}"
    else
        banner
        echo -e "Please ${red}make sure${reset} you have the ${yellow}\"${function}\"${reset} file."
        echo -e "${yellow}You need this file to execute collector${reset}!"
        exit 1
    fi
done

# Checking if is a know target to get the cursor position
check_is_known_target(){
    if [[ -n "$1" ]] && [[ -d "${output_dir}/$1" ]]; then
        echo "This is a known target."
        cursor_start_position=30
    else
        cursor_start_position=29
    fi
}

message(){
    target="$1"
    status="$2"
    if [ "${status}" == "finished" ]; then
        echo -e "${yellow}$(date +"%d/%m/%Y %H:%M")${reset} ${red}>>${reset} The reconnaissance on ${yellow}${target}${reset} ${green}finished!${reset}"
        echo "The reconnaissance on ${target} finished at $(date +"%Y%m%d %H:%M")" | notify -nc -silent -id "${notify_recon_channel}" > /dev/null
    fi
    if [ "${status}" == "failed" ]; then
        echo -e "${yellow}$(date +"%d/%m/%Y %H:%M")${reset} ${red}>>${reset} The reconnaissance on ${yellow}${target}${reset} ${red}failed!${reset}"
        echo "The reconnaissance on ${target} failed at $(date +"%Y%m%d %H:%M")" | notify -nc -silent -id "${notify_recon_channel}" > /dev/null
    fi
    unset target
    unset status
}

domain_execution(){

    if [[ "${only_web_data}" == "yes" ]]; then
        for d in $(ls -1t "${output_dir}/${domain}" | grep -Ev "log$"); do
            if [[ -s "${output_dir}/${domain}/${d}/report/web_data_urls.txt" ]]; then
                recon_dir="${output_dir}/${domain}/${d}"
                break
            fi
        done
        aquatone_files_dir="${recon_dir}/aquatone"
        nmap_dir="${recon_dir}/nmap"
        nuclei_dir="${recon_dir}/nuclei"
        report_dir="${recon_dir}/report"
        shodan_dir="${recon_dir}/shodan"
        tmp_dir="${recon_dir}/tmp"
        web_data_dir="${recon_dir}/web-data"
        web_params_dir="${recon_dir}/web-params"
        web_tech_dir="${recon_dir}/web-tech"
    fi

    echo "Directory structure created and ready to work." | tee -a "${log_execution_file}"

    (# Show the directory structure
    echo "The directory structure you will have to work with, is..."
    echo " "
    echo "${output_dir}/${domain}"
    echo -e " ├── log (${yellow}log dir for collector script execution${reset})"
    echo -e " └── $(basename "${recon_dir}")"
    echo -e "     ├── aquatone (${yellow}aquatone output files${reset})"
    echo -e "     ├── nuclei (${yellow}nuclei execution output files${reset})"
    echo -e "     ├── report (${yellow}adjust function output files${reset})"
    echo -e "     ├── tmp (${yellow}subdomains recon tmp files${reset})"
    echo -e "     ├── web-data (${yellow}web data function for gobuster and dirsearch output${reset})"
    echo -e "     ├── web-params (${yellow}web data function for katana and waybackurl output${reset})"
    echo -e "     └── web-tech (${yellow}web data function for response headers using curl or httpx output${reset})"
    echo " "
    echo -e "${red}Attention:${reset} The output from all tools used here will be placed in background and treated later."
    echo -e "\t   If you need look the output in execution time, you need to \"tail\" the files."
    echo " "
    # Execute all functions
    echo -e "${yellow}$(date +"%d/%m/%Y %H:%M")${reset} ${red}>>${reset} ${green}Reconnaissance started on${reset} ${yellow}${domain}${reset}${green}!${reset}"
    if [ "${only_web_data}" == "no" ]; then
        subdomains_recon
        joining_removing_duplicates
        diff_domains
        if [ -s "${report_dir}/domains_diff.txt" ]; then
            managing_the_files "${report_dir}/domains_diff.txt"
        else
            managing_the_files "${report_dir}/domains_found.txt"
        fi
        infra_recon
        shodan_recon
        webapp_alive
        #emails_recon
        if [ "${only_recon}" == "yes" ]; then
            message "${domain}" finished
            exit 0
        fi
    fi
    if [ "${only_web_data}" == "yes" ] && [ ! -s "${report_dir}/web_data_urls.txt" ]; then
        echo -e "${yellow}$(date +"%d/%m/%Y %H:%M")${reset} ${red}>>${reset} ${red}The reconnaissance finished 'cause an error:${reset}"
        echo -e "\t\t    You haven't the actual ${yellow}web_data_urls.txt${reset} file to collect data to analyze!"
        echo -e "\t\t    Please, run the collector with -d domain --recon or just -d domain to run recon and web data!"
        exit 1
    else
        web_data "${report_dir}/web_data_urls.txt"
        robots_txt
        web_data "${report_dir}/robots_urls.txt"
        for file in "${report_dir}/web_data_urls.txt" "${report_dir}/robots_urls.txt" ; do
            aquatone_function "${file}"
        done
        git_rebuild
    fi
    #report
    message "${domain}") finished 2>> "${log_execution_file}" | tee -a "${log_execution_file}"
}

url_execution(){
    echo "Directory structure created and ready to work." | tee -a "${log_execution_file}"

    (# Show the directory structure
    echo "The directory structure you will have to work with, is..."
    echo " "
    echo "${output_dir}/${url_domain}"
    echo -e " ├── log (${yellow}log dir for collector script execution${reset})"
    echo -e " └── $(basename "${recon_dir}")"
    echo -e "     └── ${url_base} (${yellow}specific directory for the files referring to the tested url${reset})" 
    echo -e "         ├── aquatone-data (${yellow}aquatone output files${reset})"
    echo -e "         └── report (${yellow}adjust function output files${reset})"
    echo " "
    echo -e "${red}Attention:${reset} The output from all tools used here will be placed in background and treated later."
    echo -e "\t   If you need look the output in execution time, you need to \"tail\" the files."
    echo " "
    # Executing just the functions necessary to url check
    echo -e "${yellow}$(date +"%d/%m/%Y %H:%M")${reset} ${red}>>${reset} ${green}Recon started on${reset} ${yellow}${url_base}${reset}${green}!${reset}"
    web_data "${recon_dir}/url_2_test.txt"
    robots_txt
    web_data "${report_dir}/robots_urls.txt"
    for file in "${recon_dir}/url_2_test.txt" "${report_dir}/robots_urls.txt" ; do
        aquatone_function "${file}"
    done
    git_rebuild 
    message "${url_2_verify}" finished
    rm "${recon_dir}/url_2_test.txt" > /dev/null 2>&1) 2>> "${log_execution_file}"| tee -a "${log_execution_file}"
}

# Checking the runtime parameter dependency for domain recon
check_parameter_dependency_domain(){
    [[ "${args_count}" -gt 9 ]] && echo -e "You are trying to pass a number of parameters beyond what is necessary for this collector reconnaissance option \"${yellow}-d|--domain${reset}\".\n" && usage
    if [[ ${#web_port_detect[@]} -eq 0 ]]; then
        echo -e "You need to specify at least one of these options sort (-ws|--web-short-detection) or long (-wl|--web-long-detection) web detection!\n"
        usage
    fi

    if [[ -z "${web_tool_detection}" ]]; then
        echo -e "You need to inform one of these tools ${bold}${yellow}curl${reset}${normal} or ${bold}${yellow}httpx${reset}${normal} to perform web application detection.\n"
        usage
    fi
}

if [[ -n ${domain} ]] && [[ ! -s "${domain_list}" ]] && [[ -z "${url_2_verify}" ]]; then
    echo "The reconnaissance for ${domain} started at $(date +"%Y%m%d %H:%M")" | notify -nc -silent -id "${notify_recon_channel}" > /dev/null
    clear > "$(tty)"
    echo -e "${collector_command_line}\n"
    banner
    check_parameter_dependency_domain
    check_is_known_target "${domain}"
    create_initial_directories_structure
    domain_execution
fi

if [[ -z ${domain} ]] && [[ -s "${domain_list}" ]] && [[ -z "${url_2_verify}" ]]; then
    unset domain
    while read -r domain; do 
        echo "The reconnaissance for ${domain} started at $(date +"%Y%m%d %H:%M")" | notify -nc -silent -id "${notify_recon_channel}" > /dev/null
        $(clear >&2)
        echo -e "${collector_command_line}\n"
        banner
        check_parameter_dependency_domain
        check_is_known_target "${domain}"
        create_initial_directories_structure
        if [[ $(host -t A "${domain}" | grep -E "has.address" | awk '{print $4}' | grep -E "${IPv4_regex}$" > /dev/null 2>&1 ; echo $?) -eq 0 ]]; then
            domain_execution
        else
            echo -e "${yellow}$(date +"%d/%m/%Y %H:%M")${reset} ${red}>>${reset} The ${yellow}${domain}${reset} does not exist!" | tee -a "${log_dir}/domain_doesnot_exit.txt"
            echo "The ${domain} does not exist!" | notify -nc -silent -id "${notify_recon_channel}" > /dev/null
            message "${domain}" failed
        fi
    done < "${domain_list}"
    unset domain
fi

if [[ -z ${domain} ]] && [[ ! -s "${domain_list}" ]] && [[ -n "${url_2_verify}" ]]; then
    # Checking the runtime parameter dependency for url recon
    if [[ -n "${url_2_verify}" && -n "${domain}" ]] || [[ "${#dns_wordlists[*]}" -gt 0 ]] || \
        [[ -n "${url_2_verify}" && -n "${limit_urls}" ]] || [[ -n "${url_2_verify}" && "${#excluded[*]}" -gt 0 ]]; then
        echo -e "You have specified one or more options that are not used with \"-u|--url\"!\n"
        usage
    fi

    if [[ "${args_count}" -gt 4 ]]; then
         echo -e "You are trying to pass a number of parameters beyond what is necessary for this collector reconnaissance option \"${yellow}-u|--url${reset}\".\n"
         usage
    fi
    url_base=$(echo "${url_2_verify}" | sed -e 's/http.*\/\///' | awk -F'/' '{print $1}' | xargs -I {} basename {})
    mapfile -d'.' -t url_tmp_domain <<< "${url_base}"
    for (( i=$((${#url_tmp_domain[@]}-1)); i>=0; i-- ));do
        url_domain=$(echo "${url_tmp_domain[$i]}.${url_domain}" | sed -e 's/\.$//' -e 's/^\.//' -e 's/[[:space:]]*$//')
        [[ $(host -t A "${url_domain}" | grep -v "Host.*not.found:" | awk '{print $4}' | \
            grep -E "^^([0-9]+(\.|$)){4}|^([0-9a-fA-F]{0,4}:){1,7}([0-9a-fA-F]){0,4}$") ]] && break
    done

    echo "The reconnaissance for ${url_base} started at $(date +"%Y%m%d %H:%M")" | notify -nc -silent -id "${notify_recon_channel}" > /dev/null
    clear > "$(tty)"
    echo -e "$0 $*\n"
    banner
    check_is_known_target "${url_domain}"
    create_initial_directories_structure

    [[ -s "${recon_dir}/url_2_test.txt"  ]] && rm "${recon_dir}/url_2_test.txt"

    if [[ $(echo "${url_2_verify}" | grep -qE "^(http|https)://" ; echo "$?") -eq 0 ]]; then
        echo "${url_2_verify}" > "${recon_dir}/url_2_test.txt"
    else
        [[ "200" -eq "$(curl -o /dev/null -Ls -w "%{http_code}\n" "http://${url_2_verify}")" ]] && curl -o /dev/null -Ls -w "%{url_effective}\n" "http://${url_2_verify}" > "${recon_dir}/url_2_test.txt"
        [[ "200" -eq "$(curl -o /dev/null -kLs -w "%{http_code}\n" "https://${url_2_verify}")" ]] && curl -o /dev/null -kLs -w "%{url_effective}\n" "https://${url_2_verify}" > "${recon_dir}/url_2_test.txt"
    fi

    url_execution
fi
